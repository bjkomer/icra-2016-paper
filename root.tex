%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

\overrideIEEEmargins                                      % Needed to meet printer requirements.

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
%\usepackage{graphics} % for pdf, bitmapped graphics files
\usepackage{epsfig} % for postscript graphics files
\usepackage{mathptmx} % assumes new font selection scheme installed
\usepackage{times} % assumes new font selection scheme installed
\usepackage{amsmath} % assumes amsmath package installed
%\usepackage{amssymb}  % assumes amsmath package installed

\usepackage{graphicx} % For including graphics N.B. pdftex graphics driver
\usepackage{subcaption}
% Allow symbol for degrees
\usepackage{gensymb}
% Allow descriptions under tables
\usepackage[flushleft]{threeparttable}

\title{\LARGE \bf
Adaptive Quadcopter Control using Biologically Inspired Neural Networks
}


\author{Brent Komer$^{1}$% <-this % stops a space
\thanks{$^{1}$Brent Komer is with the Computational Neuroscience Research Group, Department of Systems Design Engineering,
        University of Waterloo, N2L 3G1, Canada
        {\tt\small bjkomer@uwaterloo.ca}}%
}


\begin{document}



\maketitle
\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

This paper explores the application of a biologically inspired learning method to produce an adaptive controller for a quadcopter.
Our approach works by first generating a PD control signal based on the error from the quadcopter to its target.
State information is encoded into an ensemble of spiking Leaky Integrate-and-Fire neurons.
The Prescribed Error Sensitivity learning rule is applied to this ensemble to produce an additional control signal to be summed with the PD signal.
The resulting controller is able to learn non-linear functions of system state to account for unknown and changing dynamic properties of the quadcopter in its environment.
The algorithms used are designed to be implementable on neuromorphic hardware.
Experiments are performed in simulation to demonstrate the effectiveness of the controller.

\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{INTRODUCTION}

Humans have an exceptional ability to be able to adapt to their surroundings.
In particular the human motor control system is able to compensate for changes in forces, torques, and inertial effects on the body.
For example, when picking up an object such as a hammer, the weight of the hammer will apply external forces to the hand.
This will change the dynamic properties of the hand and arm movements, yet the human motor control system is able to easily compensate for these changes and accurately control movement with the object.
Even if an object has never been encountered before, the human brain is able to calculate the correct changes in timing and muscle tensions in order to skilfully manipulate the object.
The predictive capabilities of the brain, along with the plasticity of neural connections in the motor area help guide these sophisticated behaviours.


This ability for quick and easy adaptation to new dynamic properties of a system would be extremely useful in robotics. 
Applying similar methods of control that have been developed over millions of years of evolution in the brain to a robotic control system could result in major improvements. 
This is especially useful now that the demands of many robotic systems are now more general purpose than they were in the past. 
Robots started out mainly performing simple and repetitive tasks in stable environments, such as automation in manufacturing \cite{garcia2007evolution}. 
Now they are being used increasingly in more complex situations requiring a diverse amount of control, such as search and rescue missions, performing medical procedures, and assisting the elderly \cite{garcia2007evolution, hockstein2007history, nourbakhsh2005human, lacey1998application}. 
When the precise environment that the robot will operate in is not fully known, it is useful for any control system that the robot uses to be adaptable to those environments.

Another advantage the brain has when it comes to control, is that it uses very little power, about 20 Watts on average \cite{hart1975brain}.
% the motor is the majority of the power on a quadcopter, so neuromorphic hardware might not help much here
Hardware inspired by the brain is being designed to take advantage of this low power paradigm. 
This style of hardware, known as neuromorphic hardware, is typically massively parallel and consumes much less power than traditional hardware.
Computational power efficiency for biological systems is 8-9 orders of magnitude better than the power efficiency for digital computation \cite{hasler2013finding}.
The algorithms explored in this paper focus on being biologically plausible in order to take advantage of such hardware.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{BACKGROUND}

\subsection{Quadcopter Flight}
%TODO should dynamics equations go here too? Even though they aren't necessary for the neural controller?

The system state of a quadcopter is six dimensional: three for position ($x$, $y$, and $z$) and three for orientation (roll, pitch, and yaw). 
There are four control inputs, which are typically taken to be the rotational velocity of each of the four rotors. 
For a physical quadcopter, these inputs are the voltages applied to each of these rotors.
A transformation in these voltages can be obtained using the physical rotor parameters to estimate the rotor velocity.
For simplicity of the simulation, the velocity is used directly as the control input in this paper. 

The rotors will always generate a thrust that is perpendicular to the body of the aircraft. 
In addition to this thrust, torque is generated by each rotor based on their spin direction  as well as their distance from the center of the body.
For the quadcopter to be able to control its orientation, half of the rotors spin clockwise and the other half spin counter-clockwise. 
The pairs diagonally opposite each other across the body spin in the same direction, allowing the torques to balance one another out and the quadcopter to maintain a steady orientation. 
By varying the relative speeds of each rotor, the quadcopter is able to create a net torque in a specific direction, causing a rotation about any axis.

A quadcopter performs four common actions to move around in its environment, with a distinct pattern of rotor actuation for each one: 
tilt forward/backward, tilt left/right, rotate, and move up/down. 
A quadcopter can perform any combination of these actions, and with different magnitudes of each. The relative rotor speeds required for each are shown in \ref{fig:actions}. This set of actions make up what is referred to as the `task space' of the quadcopter in the remainder of this paper.

\begin{figure}
\centering
\includegraphics[width=0.4\textwidth]{./figures/QuadcopterMovements.JPG}
\caption{Four Primary Quadcopter Movements. Taken from \cite{harsha}}
\label{fig:actions}
\end{figure}

\subsection{Adaptive Control}

Often the kinematics and dynamics of the system being controlled are unknown, or change over time in an unknown fashion. 
A controller that works well for the system initially may no longer be ideal when the system undergoes changes. 
In this situation, it is useful to have a controller that can adapt to these changes.

The foundation of adaptive control is based on parameter estimation.
First, a mathematical model of the system to be controlled is generated based on physical laws.
This model is typically of the form shown in \eqref{eq:physical_equation}, where $q$ is the vector of state variables, $M(q)$ is a mass/inertia matrix, $C(q,\dot{q})$ is the coriolis-drag term, $g(q)$ is the gravitational force, and $\tau$ is a vector representing the input force/torque to the system.

\begin{equation} \label{eq:physical_equation}
M(q)\ddot{q} + C(q,\dot{q})\dot{q} + g(q) = \tau
\end{equation}

%TODO
%[[[[[a lot more stuff to go here, need to understand it more first]]]]]
The goal of the controller is to bring the system to a particular target state.
Typically the state as well as its derivative is desired to be controlled.
Thus, the second derivative of the state will be zero when the system has arrived at the target state.
Setting $\ddot{q}$ to be zero gives the relationship of the inputs to the rest of the state shown in \eqref{eq:input_equation}.

\begin{equation} \label{eq:input_equation}
\tau = C(q,\dot{q})\dot{q} + g(q)
\end{equation}

An estimate of $q$ and $\dot{q}$ can typically be measured, leaving the only potentially unknown quantities in the right-hand side of the equation to be the physical parameters of the system.
If these physical parameters are constant and linear with respect to the system state, the equation can be reorganized as in \eqref{eq:Y_equation}.
Here $\theta$ is a vector of constant system parameters and $Y(q,\dot{q})$ is a known matrix dependent on the system state. 
$\tau$ is the input required to keep the system in a steady state.

\begin{equation} \label{eq:Y_equation}
\tau = C(q,\dot{q})\dot{q} + g(q) = Y(q,\dot{q})\theta
\end{equation}

Often the system parameters are not fully known and an estimate needs to be used instead.
Many control applications also require the system to be able to transition to different states, rather than remain at a particular state.
The adaptive control law in \eqref{eq:Y_and_control_law} uses an estimate of the parameter vector, $\hat{\theta}$, along with a standard control law to compute the desired input to the system. Here $e$ is the state error and $K$ is a gain matrix.
More detail on this style of adaptive control law can be found in \cite{slotine1987adaptive, slotine1991applied, cheah2006adaptive}.
%TODO EDIT1 add references to Slotine papers as well as a couple quick comments about the strengths of those controllers (guaranteed to converge with sufficient exploration of space, etc)

\begin{equation} \label{eq:Y_and_control_law}
\tau = Y(q,\dot{q})\hat{\theta} + Ke
\end{equation}

The parameter estimates can be initialized to any stable value and are updated according to the relationship in \eqref{eq:Y_update_equation}.
$L$ is a learning rate parameter that determines how quickly the parameter estimates change over time in proportion to the measured error.
The parameter estimates will eventually converge on values that allow the system to be controlled with minimal error.
Given sufficient exploration of the state space, the parameter estimates are guaranteed to converge to the real values if the real values are required for optimal control \cite{slotine1987adaptive}.

\begin{equation} \label{eq:Y_update_equation}
\dot{\hat{\theta}} = LY(q,\dot{q})^{T}Ke
\end{equation}


Creating a mathematical model of a system with enough detail to account for everything is difficult. 
Assumptions and approximations must be made if the model is to be tractable. 
Moreover, external forces from the environment may influence the model, and their form may be unknown as the environment can be largely unknown. 
One way to overcome this problem is to use a set of basis functions as the model, and the weights applied to each element of the basis as the constant parameters. 
If the basis is designed such that it can represent any computable function to a reasonable degree of accuracy, it will be effective in the adaptive control problem. 
Gaussian basis functions are commonly used in adaptive control \cite{sanner1992gaussian}, but neural networks may be used as well \cite{barto1983neuronlike}.
This paper explores the application of this form of control law using basis functions that are biologically plausible spiking neurons.

\subsection{Neural Simulation}

The Neural Engineering Framework (NEF)\cite{eliasmith2004neural} provides a means of representing arbitrary vectors using the properties of neurons as a basis.
This is done through a nonlinear encoding mechanism carried out by the tuning curves of the neurons, and a weighted linear decoding of the responses of the neurons to retrieve an approximation of the vector being encoded.
A transformation can be applied to the underlying representation by specifying different weights on the linear decoding.
Any computable function can be approximated through a transform, and the degree of accuracy of the decoding is dependent on the number of neurons used and the complexity of the function.
%TODO put some simple example here about x and x**2?
%TODO talk about dynamics here, might need to fix wording, and talk about recurrent connections?
The neurons themselves are a part of a dynamical system where timing effects and filters across connections play a role in the behaviour of the system. 
%It also specifies a means of performing transformation
For more detail on the NEF, see \cite{eliasmith2007build, stewart2011neural, eliasmith2013build}. % put this line in if you think the reader might want more details.

Simulation of biological neurons is carried out by the software package Nengo \cite{bekolay2013nengo}.
This software implements the algorithms in the NEF and provides an easy to use Python interface for building complex models under this framework.
The core components of Nengo are networks, nodes, ensembles, and connections.
A network is a container for all of the components, it can contain any number of nodes, ensembles, connections, and even other networks.
There is always one base network from which the rest of the model is built.
Ensembles are groups of neurons representing a single vector. 
The dimensionality of this vector can be any positive integer.
Nodes are used when a particular part of the network is doing a computation without using neurons as the underlying representation.
Typically nodes are used as the inputs and outputs to a neural system.
Connections specify transformations between representational components (ensembles and nodes) through one-way links where the information flows from the output of the first representational component (origin) to the input of the second representational component (termination).
Connections may have a synapse model applied to them, where the information from one end of the connection is delayed by a time-step before reaching the other end and a filter with a particular time constant may be applied.
If no synaptic filter is applied, the value from the origin of the connection is sent directly to the termination of the connection during the same time step.

Nengo supports a variety of underlying neuron models for its ensembles.
The most commonly used is the Leaky Integrate-and-Fire (LIF) neuron \cite{burkitt2006review}.
%[add a brief description?]. %TODO add this description
Ensembles can also be run in direct mode, in which functions are computed explicitly rather than with neurons.
However, models in this mode are not implementable directly on neuromorphic hardware, and the behaviour of the system can be significantly different.
Nevertheless, it can be useful for constructing working prototypes in simulation before converting the entire system to an underlying neural model. %TODO: this sounds gross, fix it... %TODO EDIT1

Once the network structure has been specified, Nengo can build and run a simulation of this network for either a specified duration of time, or until a stop signal is generated. 
All timing is measured as `simulated time' with a specific time-step. 
If the time-step is short, the simulation can capture minute timing details more accurately, but the system as a whole will run slower with respect to real-time. A default time step of 1ms is typically used in Nengo models, which provides a reasonable trade-off between accuracy and run-time.
%TODO is there any justification for this?

\subsection{Adaptive Control with Nengo}

We use the adaptive control methods described above to build a quadcopter controller using Nengo. 
An ensemble of simulated neurons is used as the set of basis functions for the physical model, and the decoders of these neurons are used as the vector of unknown constant parameters. 
A biologically plausible learning rule known as the Prescribed Error Sensitivity (PES) rule is used to update the decoder values \cite{bekolay2013simultaneous}. 

This learning method works by first creating a connection from an ensemble of spiking neurons representing the state of the system to an ensemble or node representing the output of the controller. 
This is known as the `learned connection' and can be initially set to perform any transformation, but is typically initialized for the output to be random or zero. 
If the designer has an approximation of what the final learned transformation should look like, they can set this as the initial transformation. 
Doing so will allow the system to converge to the final transformation more quickly.

The learned connection will be modulated by an error signal, which can come from anywhere in the network. 
The PES learning rule will attempt to reduce the error signal by changing the value of the decoders on the learned connection. 
The direction in which the decoder values change is dependent on the sign of the error. 
The magnitude of the change in decoder values at each time step is dependent on both the magnitude of the error and a learning-rate parameter. 
The learning rate is a dimensionless parameter that needs to be tuned for the specific application. 
It is dependent on the simulation time step, the number of neurons in the state ensemble, as well as how responsive the model needs to be to changes. 
A larger learning rate will cause larger reactions to error, effectively making the system trust its current measurements more than historical ones. 
A smaller time-step means that these changes will occur more frequently, so the net change over time will be greater. 
A larger number of neurons means that the changes will be greater, as there will be more decoders changing. The overall transformation is a sum of these decoders. 

\subsection{Simulation}

The Virtual Robotics Experimentation Platform (V-REP) \cite{vrep} is used to validate and test the quadcopter controller.
This software package contains models of various robotic platforms, including a model of a quadcopter; and allows the construction of intricate 3D virtual environments for the quadcopter to interact with.
External forces can be applied to the quadcopter from within this environment.
%This simulation environment allows
%Within this environment
An example of a region within the simulation environment is shown in \ref{fig:vrep_screenshot}.

\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{./figures/VREPScreenshot.png}
\caption{Simulation Environment in V-REP}
\label{fig:vrep_screenshot}
\captionsetup{singlelinecheck=off,font=footnotesize}
\caption*{
Screen capture of an example environment in V-REP. The coloured areas with arrows represent regions of space where a wind force is applied to the quadcopter in the direction of the arrows. The blue region resembling a circuit board represents an area where an unknown non-linear force will be applied to the quadcopter. The semi-transparent green sphere is the target location. The quadcopter has reached its target in this example.}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{CONTROLLER DESIGN}

The goal of the controller is to actuate the quadcopter in such a way that it travels to a desired position in a reasonable amount of time. 
This position is specified as a set of $x$, $y$, and $z$ coordinates and a particular yaw direction. 
The controller is given the state error of the quadcopter and its target, as well as the current linear and angular velocities of the quadcopter. 
It needs to use this information to generate a suitable control signal.

\subsection{PD Signal}

The adaptive controller here consists of two parts. The first is a standard PD controller that generates a four-dimensional output signal in the space of possible quadcopter motions (task space). 
The gain matrices that perform this operation can be seen in \eqref{eq:gain_matrix_p} and \eqref{eq:gain_matrix_d}. 
This signal is then multiplied by the matrix in \eqref{eq:rotor_transform} to transform it into the four dimensional rotor velocity space, providing the actuation associated with the desired movement commands.
The design of this matrix depends upon the orientation of the rotor blades to the $x$ and $y$ axes. 
This transformation matrix assumes that the rotor axes are offset from the $x$ and $y$ axes by 45 degrees as the V-REP model used here.

\begin{equation} \label{eq:gain_matrix_p}
K_{p} =
\setcounter{MaxMatrixCols}{12}
\begin{bmatrix}
0 & 0 & k_{z} & 0 & 0 & 0 \\
0 & k_{y} & 0 & k_{\theta} & 0 & 0\\
k_{x} & 0 & 0 & 0 & k_{\phi} & 0 \\
0 & 0 & 0 & 0 & 0 & k_{\psi}
\end{bmatrix}
\end{equation}

\begin{equation} \label{eq:gain_matrix_d}
K_{d} =
\setcounter{MaxMatrixCols}{12}
\begin{bmatrix}
0 & 0 & k_{\dot{z}} & 0 & 0 & 0 \\
0 & k_{\dot{y}} & 0 & k_{\dot{\theta}} & 0 & 0\\
k_{\dot{x}} & 0 & 0 & 0 & k_{\dot{\phi}} & 0 \\
0 & 0 & 0 & 0 & 0 & k_{\dot{\psi}}
\end{bmatrix}
\end{equation}

\begin{equation} \label{eq:rotor_transform}
T_{R} = 
\begin{bmatrix}
1 & -1 & 1 & 1 \\
1 & -1 & -1 & -1 \\
1 & 1 & -1 & 1 \\
1 & 1 & 1 & -1
\end{bmatrix}
\end{equation}

\begin{equation} \label{eq:control_equation}
u = T_{R}(K_{p}e + K_{d}\dot{e})
\end{equation}
%TODO make this equation look prettier on paper. There also might need to be tildes and things on the variables to show that they are state error.

Translation in the $x$ and $y$ directions is dependent on the states of both $x$ and $y$ as well as roll and pitch, because a roll in the quadcopter causes a component of thrust to be applied in the $y$ direction, and a pitch causes a component of thrust to be applied in the $x$ direction.
A delicate balance needs to be found between each of the gains in order to create a stable, functioning controller. 
The setpoint for each of the velocities as well as for roll and pitch is zero.

%[gain matrix figures]

%[talk about egocentric state as the error]
The state error is measured relative to the body frame because most sensors on a real quadcopter would return measurements relative to the sensor device itself, which is located on the quadcopter. Absolute measurements could still be obtained with a GPS device, but would typically be much less accurate and such devices are harder to use for fine-tuned control. Using localized sensors, the state of the quadcopter can be defined relative to its target, making the state in the same coordinates as the error.

%[talk about building the model in Nengo]
Here the controller is implemented with a Nengo network, in which a 12-dimensional ensemble representing the state error can be projected to a 4-dimensional ensemble representing the desired control command. 
The transformation done through this projection will be by the 12x4 PD gain matrix of the controller resulting from the concatenation of \eqref{eq:gain_matrix_p} and \eqref{eq:gain_matrix_d}. 
This 4-dimensional ensemble is then projected to another 4-dimensional ensemble which represents the four desired angular velocities of the quadcopter's rotors. 
This projection is done through a transformation by the 4x4 rotor matrix \eqref{eq:rotor_transform}. 
This rotor velocity ensemble is connected to a node representing the physical quadcopter, which in turn feeds back into the state error ensemble. 
The network diagram is shown in \ref{fig:NetBasic}. 
The network can be simplified further by multiplying the gain matrix with the rotor matrix to give a single transformation matrix from state error to rotor velocity. 

\begin{figure}
\centering
\includegraphics[width=0.4\textwidth]{./figures/QuadcopterNetworkSimpleLegend.pdf}
\caption{Basic Quadcopter Controller Network}
\label{fig:NetBasic}
\end{figure}

\subsection{Adaptive Signal}

%TODO explain modulatory connection somewhere
To allow the system to adapt to unmodelled and changing dynamics, an ensemble of Leaky Integrate-and-Fire (LIF) neurons representing the quadcopter state is used.
A transformation from this ensemble to the task-space ensemble provides the adaptive control signal.
This transformation is initialized to be zero and is modified over time using the PES learning rule.
The PES rule seeks to build a transformation that minimizes a particular error signal.
In this case the error signal is the state error undergoing a control transform.
This control transform is often set to be the same transform that the underlying PD controller uses, but this turns out to be not ideal for a quadcopter in all scenarios.

Under normal conditions when the only external force on the quadcopter is due to gravity, using the PD control signal as the error that modulates the PES learning works fine.
This is because this modulatory signal can be brought to zero when the quadcopter is at its target, due to its stable state having roll and pitch angles of zero.
If there is an external force in the horizontal direction (such as wind) the quadcopter needs to maintain a non-zero pitch and/or roll in order to remain stationary.
Being in this state produces a non-zero PD control signal, causing the quadcopter to move away from its target until it reaches a location where the PD control signal is zero.
For each possible pair of stable roll and pitch angles there exists a pair of $x$ and $y$ displacements from the target that result in a PD control signal of zero.
These points correspond to locations in the null space of the PD gain matrix.
A simple example of this effect is shown in \ref{fig:zeroError}.

\begin{figure}
\centering
\includegraphics[width=0.4\textwidth]{./figures/ZeroErrorDiagramLabelled.png}
\caption{Unique Locations with a Control Signal of Zero}
\label{fig:zeroError}
\end{figure}

Since the PES rule is receiving no error signal in these states, no change is made to the adaptive transformation and correction for the wind cannot occur.
To solve this problem a different signal is given to the PES rule, one that is in the same form as the PD control signal except the gains used are different.
The most important difference is that the gains on the roll and pitch are set to zero, effectively ignoring these state variables.
This makes sense intuitively because what is actually desired to be controlled is only the $x$, $y$, and $z$ location and the yaw angle.
In terms of producing an error reflecting this goal, roll and pitch should be left out of the equation.
Doing so allows only one stable point in the state space to produce an error of zero, coinciding with the target state.
The PES rule will drive the system to this state in the presence of unknown external forces.
%TODO do I need a 'assuming this state is reachable / the forces are not too strong clause here? or should that be assumed?

Another issue arises when this system is run as a point-to-point controller.
Whenever the target is moved to a new location, an error will be produced, which in turn causes the transformation from the ensemble of LIF neurons to change.
Assuming the neurons are already computing the correct adaptive control signal for the dynamics of the system, simply moving the target will cause them to now compute a sub-optimal signal.
To overcome this issue, the controller needs a way to distinguish between errors caused by the target moving and errors caused by a change in system dynamics.
A simple and effective solution is to inhibit learning when the target has moved recently.
This is accomplished by applying a low-pass filter to the signal representing the target location and then taking the difference between the target location and the low-pass filtered target location.
The resulting signal becomes large when the target moves and then progressively decays back towards zero over time, as depicted in \ref{fig:TMCSignal}.
This signal is four-dimensional, corresponding to the four dimensions of state being controlled ($x$, $y$, $z$, and yaw) and is used to inhibit learning in those particular dimensions accordingly.

%TODO put in better quality figure here
\begin{figure}
\centering
%\includegraphics[width=0.4\textwidth]{./figures/TMCSignal.png}
\caption{Learning Inhibition Signal}
\label{fig:TMCSignal}
\end{figure}

\ref{fig:ImprovementComparison} compares the performance of an adaptive controller with each enhancement to one without, showing substantial improvement from these approaches.
The network diagram of the final design of the adaptive controller is shown in \ref{fig:NetFinal}.

%TODO put the proper subcaptions here
\begin{figure}
\centering
\begin{subfigure}[t]{0.15\textwidth}
\includegraphics[width=\textwidth]{./figures/LineSimpleXYposAnnotated.png}
\caption{}
\label{fig:ImprovementComparisonA}
\end{subfigure}
\begin{subfigure}[t]{0.15\textwidth}
\includegraphics[width=\textwidth]{./figures/LineAngleXYposAnnotated.png}
\caption{}
\label{fig:ImprovementComparisonB}
\end{subfigure}
\begin{subfigure}[t]{0.15\textwidth}
\includegraphics[width=\textwidth]{./figures/LineTMCXYposAnnotated.png}
\caption{}
\label{fig:ImprovementComparisonC}
\end{subfigure}
\caption{Controller Improvements}
\label{fig:ImprovementComparison}
\captionsetup{singlelinecheck=off,font=footnotesize}
\caption*{The quadcopter is initially hovering at the $x$-$y$ location (0,0) and is commanded to move to (0,1). After travelling 0.75 meters, the quadcopter enters a region which applies an external force in the positive $x$ direction. The controller needs to compensate for this unmodelled disturbance to reach the target. (a) The error signal given to the PES rule is the same as the PD control signal. (b) The error signal given to the PES rule comes from a gain matrix that masks out roll and pitch information. (c) The error signal to the PES rule does not contain roll or pitch information and is also inhibited by recent target movement.}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.4\textwidth]{./figures/QuadcopterNetworkTMCSimplifiedLegend.pdf} %TODO redo the name of the transform on this figure to match the paper better (remove TMC)
\caption{Adaptive Quadcopter Controller Network}
\label{fig:NetFinal}
\captionsetup{singlelinecheck=off,font=footnotesize}
\caption*{Network diagram of the adaptive quadcopter controller. \textit{Quadcopter} is a node that interfaces with the V-REP simulator. It takes as input the four rotor velocities coming from \textit{Motor} and outputs the 12-dimensional \textit{State Error} ($x$, $y$, $z$, roll, pitch, yaw, and their respective derivatives) as well as the 4-dimensional location of the \textit{Target} ($x$, $y$, $z$, and yaw). \textit{Target Difference} contains the difference between \textit{Target} and the value of \textit{Target} through a lowpass filter. \textit{State with Target} is a 16-dimensional ensemble containing the concatenation of its inputs, and its output undergoes a transformation to produce the error signal for the PES rule. \textit{Adaptation} is an ensemble of LIF neurons which represent the value of \textit{State Error}. \textit{Task} is a 4-dimensional ensemble representing the task-space control signal. Its input is the sum of the \textit{State Error} multiplied by a 12x4 gain matrix and the non-linear learned transformation from \textit{Adaptation}. The output of \textit{Task} is multiplied by a 4x4 matrix which transforms the signal into the appropriate rotor velocities to actuate the system.}
\end{figure}

\subsection{Gain Tuning}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{EXPERIMENTS}

%TODO Put in loop figures in this section somewhere

\subsection{Metrics}

Three metrics are used to evaluate performance on these tasks. 
The first is the Root Mean Squared (RMS) error of the difference between the quadcopter's current state and its target state.
The quadcopter's state consists of position, velocity, orientation, and angular velocity.
These state variables are combined by computing the length of the resulting 12-dimensional error vector to produce a single quantity.
This value is calculated at each time-step for the duration of the run and then averaged by the number of time-steps in the run.
For point to point control this error is sometimes not the most informative because as soon as the target point has changed a large error value will be recorded even if the quadcopter is moving optimally towards its target.

The second metric is a modified version of the RMS error designed to take the desired trajectory into account.
This works by ignoring any error along the direction to the target as long as the current velocity is also in that direction.
It also ignores any error caused by the velocity in the correct direction as long as the quadcopter is not currently at its target.
There are also weights placed on specific types of errors to reflect an increased desire to minimize those errors.
For example, errors caused by overshooting the target are weighted more heavily.

The third metric is the time taken for the quadcopter to reach its target within a particular tolerance. 
This metric favours controllers that can reach the target quickly.
This metric does not worry about overshoot and non-optimal trajectories as long as steady state is achieved at the target in the end.
The particular tolerance chosen for these experiments is maintaining an RMS error of less than 0.001 for a duration of one second.

The majority of the benchmarks performed in this paper will report results using the trajectory RMS error and the time-to-target metric.
The RMS metrics were recorded over a 30 second simulation time.
The time-to-target trials were also run for a total of 30 seconds and a value of 30 is recorded if the quadcopter never reaches its target within tolerance over that duration.

\subsection{Benchmarks}
\subsection{Improvement over Time}

The previous experiments only track performance for a single short run. 
The neural adaptive controllers are able to learn how to move throughout their environment better over time.
An example of this ability is shown in \ref{fig:loop_path}.
The quadcopter is commanded to move back and forth between two points on the x-y plane ([0,0] and [3,0]) with a 5 second delay between each new command.
An external force is being applied to the quadcopter along the $y$ direction proportional to its $x$ direction velocity.
This causes the path of the quadcopter to become curved rather than a straight line.
Over time, the neural adaptive TMCA controller begins to compensate for this external force, and the path between the two points starts to converge towards a straight line.
The non-adaptive controllers show no such improvement over time.

\begin{figure}
\centering
\includegraphics[width=0.32\textwidth]{./figures/LoopAdaptive.png}
\includegraphics[width=0.32\textwidth]{./figures/LoopPD.png}
\includegraphics[width=0.32\textwidth]{./figures/LoopPIDName.png}
\caption{Path of Quadcopter between Two Points with External Forces} %mention something about how the experiment was done here? it was 100 seconds total with 5 seconds before the point switches
\label{fig:loop_path}
\captionsetup{singlelinecheck=off,font=footnotesize}
\caption*{
RMS values for the Neural Adaptive TMCA, PD, and PIDtf controllers are 0.6729, 1.2827, and 1.7662 respectively. These values were calculated using the deviation from the line formed by the two target points as the error.}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{CONCLUSIONS}

This paper presents an adaptive control system for a quadcopter using simulated biological neurons.


\addtolength{\textheight}{-12cm}   % This command serves to balance the column lengths
                                  % on the last page of the document manually. It shortens
                                  % the textheight of the last page by a suitable amount.
                                  % This command does not take effect until the next page
                                  % so it should come on the page before the last. Make
                                  % sure that you do not shorten the textheight too much.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section*{ACKNOWLEDGMENT}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,root}
\nocite{*}
%TODO clean up the reference style to look good in IEEE format
%TODO reference thesis

\end{document}
