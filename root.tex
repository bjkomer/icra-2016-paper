%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8
\pdfminorversion=4
\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

\overrideIEEEmargins                                      % Needed to meet printer requirements.

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
%\usepackage{graphics} % for pdf, bitmapped graphics files
\usepackage{epsfig} % for postscript graphics files
\usepackage{mathptmx} % assumes new font selection scheme installed
\usepackage{times} % assumes new font selection scheme installed
\usepackage{amsmath} % assumes amsmath package installed
%\usepackage{amssymb}  % assumes amsmath package installed

\usepackage{graphicx} % For including graphics N.B. pdftex graphics driver
\usepackage{subcaption}
% Allow symbol for degrees
\usepackage{gensymb}
% Allow descriptions under tables
\usepackage[flushleft]{threeparttable}
% Allow math symbols to be bolded
\usepackage{bm}

\title{\LARGE \bf
Adaptive Quadcopter Control using Spiking Neural Networks
}


\author{Brent Komer$^{1}$ and Chris Eliasmith$^{1}$% <-this % stops a space
\thanks{$^{1}$Brent Komer and Chris Eliasmith are with the Center for Theoretical Neuroscience, Department of Systems Design Engineering,
        University of Waterloo, N2L 3G1, Canada
        {\tt\small bjkomer@uwaterloo.ca}}%
}


\begin{document}



\maketitle
\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

This paper explores the application of a biologically inspired learning method for spiking neural networks to produce an adaptive controller for a quadcopter.
%TODO talk more about motivation and results here, make sentences 2-4 less disconnected
%Our approach works by first generating a PD control signal based on the error from the quadcopter to its target.
%State information is encoded into an ensemble of spiking neurons.
%The Prescribed Error Sensitivity learning rule is applied to this ensemble to produce an additional control signal to be summed with the PD signal.
This controller is able to learn non-linear functions of system state to account for unknown and changing dynamic properties of the quadcopter in its environment.
The algorithms used are designed to run efficiently on neuromorphic hardware.
Experiments performed in simulation demonstrate the effectiveness of the controller.
On average the adaptive controller reached its target 15\% faster and with 69\% less error than the best non-adaptive PID controller tested.

\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

The human motor control system is able to effectively compensate for changes in forces, torques, and inertial effects on the body.
%sticking there together
This ability to adapt to new dynamic properties of a system is extremely useful in robotics.
When the precise environment that the robot will operate in is not fully known, or if there are unmodelled dynamics in the robot itself, it is useful for a control system that the robot uses to be adaptable to those environments.

Recently, hardware inspired by the brain is being designed to take advantage of low power computation that borrows techniques from neural computation \cite{hasler2013finding, khan2008spinnaker, boahen2006neurogrid}.
Such neuromorphic hardware is massively parallel and consumes much less power than traditional hardware.
Computational power efficiency for these systems is currently about 4 orders of magnitude better than the power efficiency for standard hardware \cite{hasler2013finding}.
The algorithms explored in this paper focus on being able to take advantage of such hardware.

Specifically we develop and test a spiking, adaptive controller for use on a quadcopter platform.
The simulated environment in which the quadcopter operates varies dramatically, causing changes in the dynamic properties of the system (e.g. changing wind conditions, or picking up a load of unknown mass).
In this paper, we describe the design of the controller, it's mapping to spiking neurons, and demonstrate it's performance compared to standard and non-spiking controllers across five tasks.
We show that this adaptive controller has the best performance of those tested.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Background}

\subsection{Quadcopter Flight}

The system state of the quadcopter is six dimensional: three for position ($x$, $y$, and $z$) and three for orientation (roll, pitch, and yaw). 
There are four control inputs, which are typically taken to be the rotational velocity of each of the four rotors. For simplicity of the physical simulation, the velocity is used directly as the control input in this paper. 

The rotors always generate a thrust that is perpendicular to the body of the aircraft. 
In addition to this thrust, torque is generated by each rotor based on their spin direction  as well as their distance from the center of the body.

In general, a quadcopter uses these forces to perform four common actions to move around in its environment, with a distinct pattern of rotor actuation for each one: 
tilt forward/backward, tilt left/right, rotate, and move up/down. 
A quadcopter can perform any combination of these actions, and with different magnitudes of each. The relative rotor speeds required for each are shown in Figure \ref{fig:actions}. This set of actions make up the `task space' of the quadcopter.

\begin{figure}
\centering
\includegraphics[width=0.4\textwidth]{./figures/QuadcopterMovements.JPG}
\caption{Four Primary Quadcopter Movements. \cite{harsha}}
\label{fig:actions}
\end{figure}

\subsection{Adaptive Control}

Often the kinematics and dynamics of the system being controlled are unknown, or change over time in an unknown fashion. 
A controller that works well for the system initially may no longer be ideal when the system undergoes changes. 
In this situation, it is useful to have a controller that can adapt to these changes.

The foundation of adaptive control is based on parameter estimation.
First, a mathematical model of the system to be controlled is generated based on physical laws.
This model is typically of the form shown in \eqref{eq:physical_equation}, where $q$ is the vector of state variables, $M(q)$ is a mass/inertia matrix, $C(q,\dot{q})$ is the coriolis-drag term, $g(q)$ is the gravitational force, and $\tau$ is a vector representing the input force/torque to the system.

\begin{equation} \label{eq:physical_equation}
M(q)\ddot{q} + C(q,\dot{q})\dot{q} + g(q) = \tau
\end{equation}

The goal of the controller is to bring the system to a particular target state.
Typically the state as well as its derivative is desired to be controlled.
Thus, the second derivative of the state will be zero when the system has arrived at the target state.
Setting $\ddot{q}$ to be zero gives the relationship of the inputs to the rest of the state shown in \eqref{eq:input_equation}.

\begin{equation} \label{eq:input_equation}
\tau = C(q,\dot{q})\dot{q} + g(q)
\end{equation}

An estimate of $q$ and $\dot{q}$ can typically be measured, leaving the only potentially unknown quantities in the right-hand side of the equation to be the physical parameters of the system.
If these physical parameters are constant and linear with respect to the system state, the equation can be reorganized as in \eqref{eq:Y_equation}.
Here $\theta$ is a vector of constant system parameters and $Y(q,\dot{q})$ is a known matrix dependent on the system state. 
$\tau$ is the input required to keep the system in a steady state.

\begin{equation} \label{eq:Y_equation}
\tau = C(q,\dot{q})\dot{q} + g(q) = Y(q,\dot{q})\theta
\end{equation}

Often the system parameters are not fully known and an estimate needs to be used instead.
Many control applications also require the system to be able to transition to different states, rather than remain at a particular state.
The adaptive control law in \eqref{eq:Y_and_control_law} uses an estimate of the parameter vector, $\hat{\theta}$, along with a standard control law to compute the desired input to the system. Here $e$ is the state error and $K$ is a gain matrix.
More detail on this style of adaptive control law can be found in \cite{slotine1987adaptive}, \cite{slotine1991applied}, and \cite{cheah2006adaptive}.

\begin{equation} \label{eq:Y_and_control_law}
\tau = Y(q,\dot{q})\hat{\theta} + Ke
\end{equation}

The parameter estimates are initialized to any stable value and are updated according to the relationship in \eqref{eq:Y_update_equation}.
$L$ is a learning rate parameter that determines how quickly the parameter estimates change over time in proportion to the measured error.
The parameter estimates will eventually converge on values that allow the system to be controlled with minimal error.
Given sufficient exploration of the state space, the parameter estimates are guaranteed to converge to the ideal values if the ideal values are required for optimal control \cite{slotine1987adaptive}.

\begin{equation} \label{eq:Y_update_equation}
\dot{\hat{\theta}} = LY(q,\dot{q})^{T}Ke
\end{equation}

Defining the necessary mathematical model of the system with sufficient detail is difficult. 
Assumptions and approximations must often be made if the model is to be tractable. 
Moreover, external forces from the environment may influence the model, and their form may be unknown as the environment is often largely unknown. 
One way to overcome this problem is to use a set of basis functions as the model, and the weights applied to each element of the basis as the constant parameters. 
If the basis is designed such that it can represent any computable function to a reasonable degree of accuracy, it will be effective in the adaptive control problem. 
Gaussian basis functions are commonly used in adaptive control \cite{sanner1992gaussian}, but neural networks may be used as well \cite{barto1983neuronlike}.
This paper employs biologically plausible spiking neurons as basis functions in this form of control law.

\subsection{Neural Simulation}

The first principle Neural Engineering Framework (NEF)\cite{eliasmith2004neural} provides a means of representing vectors using the properties of neurons as a basis.
This is done through a nonlinear encoding mechanism carried out by the tuning curves of the neurons, and a weighted linear decoding of the responses of the neurons to retrieve an approximation of the vector being encoded.
The second NEF principle \eqref{eq:SecondPrinciple} is that a transformation can be applied to the underlying representation by specifying different weights on the linear decoding.% \eqref{eq:SecondPrinciple}.

\begin{equation} \label{eq:SecondPrinciple}
\hat{f}(x) = \sum_{i} a_{i} x d_{i}^{f}
\end{equation}

Where $a_{i}$ is the neural activity and $d_{i}^{f}$ are the optimal linear decoders for computing the function $f$.
Any computable function can be approximated through such a transform, and the degree of accuracy of the decoding is dependent on the number of neurons used and the complexity of the function.
The third principle \eqref{eq:ThirdPrinciple} combines the first two to allow the implementation of linear and nonlinear dynamical systems specified in the vector space to be simulated directly in spiking neurons.
Consequently, the neurons themselves are a part of a dynamical system where timing effects and filters across connections play a role in the behaviour of the system.% \eqref{eq:ThirdPrinciple}. 

\begin{equation} \label{eq:ThirdPrinciple}
a_i(t) = G_i [ \alpha_i \langle e_i ( h_i(t)  * f(x(t)) ) \rangle + J^{bias}_i ]
\end{equation}

Where $G_{i}$ is a neural nonlinearity and $\alpha$ and $J^{bias}$ are the gain and bias determining the neuron response function. The $h(t)$ is the post-synaptic response, and the vector $e$ acts as an encoder into the state space, which accounts for the neuron tuning curve.
For more detail on the NEF, see \cite{eliasmith2004neural}.%, stewart2011neural, eliasmith2013build}. % put this line in if you think the reader might want more details.

The software package Nengo \cite{bekolay2013nengo} implements the principles of the NEF and provides an easy to use Python interface for building complex models.
The core components of Nengo are networks, nodes, ensembles, and connections.
Ensembles are groups of neurons, connections link ensembles or nodes, nodes provide arbitrary input or output to/from the model, and networks are containers for any of the components, to help conceptually organize the network.

Nengo supports a variety of underlying neuron models in its ensembles.
The most commonly used is the Leaky Integrate-and-Fire (LIF) neuron \cite{burkitt2006review}.
Ensembles can also be run in direct mode, in which functions are computed explicitly rather than with neurons.

Once a high-level network structure has been specified that implements a specific dynamical system, Nengo can build and run a simulation of this network for either a specified duration of time, or until a stop signal is generated. 
A default time step of 1ms is typically used in Nengo models, which provides a reasonable trade-off between accuracy and run-time.

\subsection{Adaptive Control with Nengo}

We use the adaptive control methods described above to build a quadcopter controller using Nengo.
Initially, the three principles are used to embed a standard PD controller into spiking neurons.
Then, an ensemble of simulated neurons is used as a set of basis functions for the physical model, and the decoders of these neurons are used as the vector of unknown constant parameters.
A biologically plausible learning rule able to learn NEF networks known as the Prescribed Error Sensitivity (PES) rule is used to update the decoder values \cite{bekolay2013simultaneous}. 

To exploit PES, we first create a connection from an ensemble of spiking neurons representing the state of the system to an ensemble or node representing the output of the controller. 
This is known as the `learned connection' and can be initially set to perform any transformation, but is typically initialized for the output to be random or zero.

The learned connection is modulated by an error signal, which in this case is the difference between the current state and the target state of the quadcopter.
The PES learning rule \eqref{eq:PES} reduces the error signal $\bm{E}$ by changing the value of the decoders $\bm{d_{i}}$ on the learned connection. 
The direction in which the decoder values change is dependent on the sign of the error. 
The magnitude of the change in decoder values for the $i$th neuron at each time step is dependent on both the magnitude of the error, a learning-rate parameter $\kappa$, and the activity of the neuron $a_{i}$. 
The learning rate is a dimensionless parameter that needs to be tuned for the specific application. 

\begin{equation} \label{eq:PES}
\Delta \bm{d_{i}} = \kappa \bm{E} a_{i}
\end{equation}

A larger number of neurons means that the changes will be greater, as there will be more decoders changing. The overall transformation is a weighted sum of these decoders and the neuron tuning curves. 

\subsection{Simulation}

The Virtual Robotics Experimentation Platform (V-REP) \cite{vrep} is used to validate and test the quadcopter controller.
This software package includes a model of a quadcopter, and allows the construction of intricate 3D virtual environments for the quadcopter to interact with.
External forces can be applied to the quadcopter from within this environment.
An example of a region within the simulation environment is shown in Figure \ref{fig:vrep_screenshot}.

\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{./figures/VREPScreenshot.png}
\caption{Simulation Environment in V-REP}
\label{fig:vrep_screenshot}
\captionsetup{singlelinecheck=off,font=footnotesize}
\caption*{
Screen capture of an example environment in V-REP. The coloured areas with arrows represent regions of space where a wind force is applied to the quadcopter in the direction of the arrows. The blue region resembling a circuit board represents an area where an unknown non-linear force will be applied to the quadcopter. The semi-transparent green sphere is the target location. The quadcopter has reached its target in this example.}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Controller Design}

The goal of the controller is to actuate the quadcopter in such a way that it travels to a desired position in a straight line. 
This position is specified as a set of $x$, $y$, and $z$ coordinates and a particular yaw direction. 
The controller is given the state error of the quadcopter and its target, as well as the current linear and angular velocities of the quadcopter. 
It needs to use this information to generate a suitable control signal.

\subsection{PD Signal}

The adaptive controller here consists of two parts. The first is a standard PD controller that generates a four-dimensional output signal in the space of possible quadcopter motions (task space). 
The gain matrices that perform this operation can be seen in \eqref{eq:gain_matrix_p} and \eqref{eq:gain_matrix_d}. 
This signal is then multiplied by the matrix in \eqref{eq:rotor_transform} to transform it into the four dimensional rotor velocity space, providing the actuation associated with the desired movement commands.
The design of this matrix depends upon the orientation of the rotor blades to the $x$ and $y$ axes. 
This transformation matrix assumes that the rotor axes are offset from the $x$ and $y$ axes by 45 degrees as the V-REP model used here.

\begin{equation} \label{eq:gain_matrix_p}
K_{p} =
\setcounter{MaxMatrixCols}{12}
\begin{bmatrix}
0 & 0 & k_{z} & 0 & 0 & 0 \\
0 & k_{y} & 0 & k_{\theta} & 0 & 0\\
k_{x} & 0 & 0 & 0 & k_{\phi} & 0 \\
0 & 0 & 0 & 0 & 0 & k_{\psi}
\end{bmatrix}
\end{equation}

\begin{equation} \label{eq:gain_matrix_d}
K_{d} =
\setcounter{MaxMatrixCols}{12}
\begin{bmatrix}
0 & 0 & k_{\dot{z}} & 0 & 0 & 0 \\
0 & k_{\dot{y}} & 0 & k_{\dot{\theta}} & 0 & 0\\
k_{\dot{x}} & 0 & 0 & 0 & k_{\dot{\phi}} & 0 \\
0 & 0 & 0 & 0 & 0 & k_{\dot{\psi}}
\end{bmatrix}
\end{equation}

\begin{equation} \label{eq:rotor_transform}
T_{R} = 
\begin{bmatrix}
1 & -1 & 1 & 1 \\
1 & -1 & -1 & -1 \\
1 & 1 & -1 & 1 \\
1 & 1 & 1 & -1
\end{bmatrix}
\end{equation}

\begin{equation} \label{eq:control_equation}
u = T_{R}(K_{p}e + K_{d}\dot{e})
\end{equation}

Translation in the $x$ and $y$ directions is dependent on the states of both $x$ and $y$ as well as roll and pitch, because a roll in the quadcopter causes a component of thrust to be applied in the $y$ direction, and a pitch causes a component of thrust to be applied in the $x$ direction.
A delicate balance needs to be found between each of the gains in order to create a stable, functioning controller. 
The setpoint for each of the velocities as well as for roll and pitch is zero.

The state error is measured relative to the body frame because most sensors on a real quadcopter would return measurements relative to the sensor device itself, which is located on the quadcopter. Using localized sensors, the state of the quadcopter can be defined relative to its target, making the state in the same coordinates as the error.

Here the controller is implemented with a Nengo network, in which a 12-dimensional ensemble representing the state error can be projected to a 4-dimensional ensemble representing the desired control command. 
The transformation done through this projection will be by the 12x4 PD gain matrix of the controller resulting from the concatenation of \eqref{eq:gain_matrix_p} and \eqref{eq:gain_matrix_d}. 
This 4-dimensional ensemble is then projected to another 4-dimensional ensemble which represents the four desired angular velocities of the quadcopter's rotors. 
This projection is done through a transformation by the 4x4 rotor matrix \eqref{eq:rotor_transform}. 
This rotor velocity ensemble is connected to a node representing the physical quadcopter, which in turn feeds back into the state error ensemble. 
The network diagram is shown in Figure \ref{fig:NetBasic}. 
The network can be simplified further by multiplying the gain matrix with the rotor matrix to give a single transformation matrix from state error to rotor velocity. 

\begin{figure}
\centering
\includegraphics[width=0.4\textwidth]{./figures/QuadcopterNetworkSimpleLegend.pdf}
%\includegraphics[width=0.4\textwidth]{./figures/PDICRASmaller.pdf}
\caption{Basic Quadcopter Controller Network for PD Control}
\label{fig:NetBasic}
\end{figure}

\subsection{Adaptive Signal}

To allow the system to adapt to unmodelled and changing dynamics, an ensemble of LIF neurons representing the quadcopter state is used as described in section D.
In this case the error signal is the state error undergoing a control transform.
This control transform is typically set to be the same transform that the underlying PD controller uses, but this turns out to be not ideal for a quadcopter in all scenarios.

Under normal conditions the only external force on the quadcopter is due to gravity, however, if there is an external force in the horizontal direction (such as wind) the quadcopter needs to maintain a non-zero pitch and/or roll in order to remain stationary.
Being in this state produces a non-zero PD control signal, causing the quadcopter to move away from its target until it reaches a location where the PD control signal is zero.
For each possible pair of stable roll and pitch angles there exists a pair of $x$ and $y$ displacements from the target that result in a PD control signal of zero.
These points correspond to locations in the null space of the PD gain matrix.
A simple example of this effect is shown in Figure \ref{fig:zeroError}.

\begin{figure}
\centering
\includegraphics[width=0.4\textwidth]{./figures/ZeroErrorDiagramLabelled.png}
\caption{Unique Locations with a Control Signal of Zero}
\label{fig:zeroError}
\end{figure}

Since the PES rule is receiving no error signal in these states, no change is made to the adaptive transformation and correction for the wind cannot occur.
To solve this problem a different signal is given to the PES rule, one that is in the same form as the PD control signal except the gains used are different.
The most important difference is that the gains on the roll and pitch are set to zero, effectively ignoring these state variables.
This is appropriate because we want to control only the $x$, $y$, and $z$ location and the yaw angle.
In terms of producing an error reflecting this goal, roll and pitch should be left out of the equation.
Doing so allows only one stable point in the state space to produce an error of zero, coinciding with the target state.
The PES rule will drive the system to this state in the presence of unknown external forces.

Another issue arises when this system is run as a point-to-point controller.
Whenever the target is moved to a new location, an error will be produced, which in turn causes the transformation from the ensemble of LIF neurons to change.
Assuming the neurons are already computing the correct adaptive control signal for the dynamics of the system, moving the target will cause them to now compute a sub-optimal signal.
To overcome this issue, the controller needs a way to distinguish between errors caused by the target moving and errors caused by a change in system dynamics.
A simple and effective solution is to inhibit learning when the target has moved recently.
This is accomplished by applying a low-pass filter to the signal representing the target location and then taking the difference between the target location and the low-pass filtered target location.
The resulting signal becomes large when the target moves and then progressively decays back towards zero over time. %, as depicted in Figure \ref{fig:TMCSignal}.
This signal is four-dimensional, corresponding to the four dimensions of state being controlled ($x$, $y$, $z$, and yaw) and is used to inhibit learning in those particular dimensions accordingly.

%%TODO put in better quality figure here
%\begin{figure}
%\centering
%\includegraphics[width=0.2\textwidth]{./figures/TMCPlot1.png}
%\includegraphics[width=0.2\textwidth]{./figures/TMCPlot2.png}
%\caption{Learning Inhibition Signal}
%\label{fig:TMCSignal}
%\captionsetup{singlelinecheck=off,font=footnotesize}
%\caption*{\textit{Blue}: Target location changing after three seconds. \textit{Green}: Lowpass filter applied to the target location signal. \textit{Red}: Difference between the target and the filtered target signal.}
%\end{figure}

Figure \ref{fig:ImprovementComparison} compares the performance of an adaptive controller with each enhancement to one without, showing substantial improvement from these approaches.
The network diagram of the final design of the adaptive controller is shown in Figure \ref{fig:NetFinal}.
For further details see \cite{komer2015biologically}.

\begin{figure}
\centering
\begin{subfigure}[t]{0.15\textwidth}
\includegraphics[width=\textwidth]{./figures/LineSimpleXYposAnnotated.png}
\caption{}
\label{fig:ImprovementComparisonA}
\end{subfigure}
\begin{subfigure}[t]{0.15\textwidth}
\includegraphics[width=\textwidth]{./figures/LineAngleXYposAnnotated.png}
\caption{}
\label{fig:ImprovementComparisonB}
\end{subfigure}
\begin{subfigure}[t]{0.15\textwidth}
\includegraphics[width=\textwidth]{./figures/LineTMCXYposAnnotated.png}
\caption{}
\label{fig:ImprovementComparisonC}
\end{subfigure}
\caption{Controller Improvements}
\label{fig:ImprovementComparison}
\captionsetup{singlelinecheck=off,font=footnotesize}
\caption*{The quadcopter is initially hovering at the $x$-$y$ location [0,0] and is commanded to move to [0,1]. After travelling 0.75 meters, the quadcopter enters a region which applies an external force in the positive $x$ direction. The controller needs to compensate for this unmodelled disturbance to reach the target. (a) The error signal given to the PES rule is the same as the PD control signal. (b) The error signal given to the PES rule comes from a gain matrix that masks out roll and pitch information. (c) The error signal to the PES rule does not contain roll or pitch information and is also inhibited by recent target movement. The latter generates the shortest path and reaches the target soonest.}
\end{figure}

\begin{figure}
\centering
%\includegraphics[width=0.4\textwidth]{./figures/QuadcopterNetworkTMCSimplifiedICRALegend.pdf}
\includegraphics[width=0.48\textwidth]{./figures/AdaptiveICRASmall.pdf}
\caption{Adaptive Quadcopter Controller Network}
\label{fig:NetFinal}
\captionsetup{singlelinecheck=off,font=footnotesize}
\caption*{Network diagram of the adaptive quadcopter controller. \textit{Quadcopter} is a node that interfaces with the V-REP simulator. It takes as input the four rotor velocities coming from \textit{Motor} and outputs the 12-dimensional \textit{State Error} ($x$, $y$, $z$, roll, pitch, yaw, and their respective derivatives) as well as the 4-dimensional location of the \textit{Target} ($x$, $y$, $z$, and yaw). \textit{Target Difference} contains the difference between \textit{Target} and the value of \textit{Target} through a lowpass filter. \textit{State with Target} is a 16-dimensional ensemble containing the concatenation of its inputs, and its output undergoes a transformation to produce the error signal for the PES rule. \textit{Adaptation} is an ensemble of LIF neurons which represent the value of \textit{State Error}. \textit{Task} is a 4-dimensional ensemble representing the task-space control signal. Its input is the sum of the \textit{State Error} multiplied by a 12x4 gain matrix and the non-linear learned transformation from \textit{Adaptation}. The output of \textit{Task} is multiplied by a 4x4 matrix which transforms the signal into the appropriate rotor velocities to actuate the system.}
\end{figure}

\subsection{Gain Tuning}

The adaptive control system in Figure \ref{fig:NetFinal} contains twelve different gains that need to be tuned.
Eight of these are for the PD gain matrix, and four are for the gain matrix of the PES rule error signal.
Due to the difficulty in tuning these gains manually, the automated parameter optimization software Hyperopt \cite{bergstra2015hyperopt} was used to tune all twelve gains simultaneously.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experiments}

\subsection{Benchmarks}

In order to evaluate the effectiveness of the adaptive controller against more conventional controllers, a set of benchmark tasks is used.
The tasks chosen involve movement in the horizontal direction under the influence of five different external force conditions: no force, a constant horizontal force, a horizontal force that is a function of the quadcopter's position, a horizontal force that is a function of the quadcopter's velocity, and a vertical force that is a function of the quadcopter's velocity.
Each task is run with three different target distance conditions: one meter, two meters, and three meters from the starting location.

A set of PID controllers are created as reference implementations to compare with the neural adaptive controller.
The PID controller designs vary with respect to two parameters; the size of the integral gain and the error signal to use.
The integral gain is chosen to be fast or slow, and the error signal either comes from the regular control transform or the adaptive transform.
Each parameter combination is used to produce four PID controllers to test. 
An ensemble of 3000 LIF neurons is used in the neural adaptive controller for these experiments.
All controllers use the same set of PD gains for consistency.

\subsection{Metrics}

Two metrics are used to evaluate performance on these tasks. 
The first is the Root Mean Squared (RMS) error of the difference between the quadcopter's current state and its desired trajectory.
The quadcopter's state consists of position, velocity, orientation, and angular velocity.
These state variables are combined by computing the length of the resulting 12-dimensional error vector to produce a single quantity.
This value is calculated at each time-step for the duration of the run and then averaged by the number of time-steps in the run.

The second metric is the time taken for the quadcopter to reach its target within a particular tolerance. 
This metric favours controllers that can reach the target quickly.
This metric does not worry about overshoot and non-optimal trajectories as long as steady state is achieved at the target in the end.
The particular tolerance chosen for these experiments is maintaining an RMS error of less than 0.001 for a duration of one second.

Both metrics are recorded over a 30 second simulation time.
A value of 30 is recorded in the time-to-target trials if the quadcopter never reaches its target within tolerance over that duration.

\subsection{Results}

Results from the benchmark tasks are displayed in Figure \ref{fig:Benchmarks}.
The adaptive controller performed as well or better than all other controllers across the tasks and metrics.
Consequently it demonstrates the overall best performance.
The mean across all trials of each task is depicted in Figure \ref{fig:OverallPerformance}.
The neural adaptive controller reached the target 15\% faster and with 69\% less error than the second best controller tested.

\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{./figures/BarIcraMedLimitRMSLabel.png}
\includegraphics[width=0.5\textwidth]{./figures/BarIcraMedLimitTimeLabel.png}
\caption{Performance on Benchmark Tasks}
\label{fig:Benchmarks}
\captionsetup{singlelinecheck=off,font=footnotesize}
\caption*{The performance of five different quadcopter controllers are compared across five benchmark tasks using two metrics. \textit{Neural Adaptive} is the adaptive controller introduced in this paper. \textit{PID SA} is a PID controller with a slow integral gain and uses the Adaptive Transform to calculate the integral. \textit{PID FA} is a PID controller with a fast integral gain and uses the Adaptive Transform to calculate the integral. \textit{PID SC} is a PID controller with a slow integral gain and uses the Control Transform to calculate the integral. \textit{PID FC} is a PID controller with a fast integral gain and uses the Control Transform to calculate the integral.}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.22\textwidth]{./figures/MeanRMSLabel.png}
\includegraphics[width=0.22\textwidth]{./figures/MeanTimeLabel.png}
\caption{Overall Performance}
\label{fig:OverallPerformance}
\captionsetup{singlelinecheck=off,font=footnotesize}
\caption*{Mean performance across all five tasks. The neural adaptive controller scores the best on both metrics.}
\end{figure}


\subsection{Improvement over Time}

The previous experiments only track performance for a single short run. 
The neural adaptive controller is able to learn how to move throughout its environment better over time.
An example of this ability is shown in Figure \ref{fig:loop_path}.
The quadcopter is commanded to move back and forth between two points on the x-y plane ([0,0] and [3,0]) with a 5 second delay between each new command.
An external force is being applied to the quadcopter along the $y$ direction proportional to its $x$ direction velocity.
This causes the path of the quadcopter to become curved rather than a straight line.
Over time, the neural adaptive controller begins to compensate for this external force, and the path between the two points starts to converge towards a straight line.
The non-adaptive controllers show no such improvement over time.
Consequently, there are classes of control problems that the adaptive neural controller can solve that can not be addressed by standard controllers.

\begin{figure}
\centering
\includegraphics[width=0.15\textwidth]{./figures/LoopAdaptive.png}
\includegraphics[width=0.15\textwidth]{./figures/LoopPD.png}
\includegraphics[width=0.15\textwidth]{./figures/LoopPIDName.png}
\caption{Path of Quadcopter between Two Points with External Forces}
\label{fig:loop_path}
\captionsetup{singlelinecheck=off,font=footnotesize}
\caption*{
RMS values for the Neural Adaptive, PD, and PID controllers are 0.6729, 1.2827, and 1.7662 respectively. These values were calculated using the deviation from the line formed by the two target points as the error.}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion and Future Work}

This paper presents an adaptive control system for a quadcopter using simulated spiking neurons.
The controller is able to learn nonlinear functions of state to produce an adaptive control signal capable of accounting for unmodelled system dynamics to bring the quadcopter to its target.
Performance of the controller in a virtual environment is better than standard control benchmarks, warranting future work implementing the algorithm on physical hardware.
The algorithms chosen have the capability to be run on neuromorphic harware, leveraging this massively parallel and low power computing paradigm.




\addtolength{\textheight}{-12cm}   % This command serves to balance the column lengths
                                  % on the last page of the document manually. It shortens
                                  % the textheight of the last page by a suitable amount.
                                  % This command does not take effect until the next page
                                  % so it should come on the page before the last. Make
                                  % sure that you do not shorten the textheight too much.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section*{Acknowledgment}

This work was supported by CFI and OIT infrastructure funding and grants from Canada Research Chairs, NSERC Discovery grant 261453, ONR grant N000141310419, AFOSR grant FA8655-13-1-3084 and OGS graduate funding.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,root}

\end{document}
